{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "using DataFrames\n",
    "using CSV\n",
    "using Statistics\n",
    "using Printf\n",
    "import MultivariateStats\n",
    "import GLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = DataFrame(CSV.File(\"./tree-sitter-analyzer/outputs/all.csv\"))\n",
    "data[ismissing.(data.group), :group] .= \"whatever\"\n",
    "data.filesize = data.statements_total .+ data.expressions_total\n",
    "data.isjupyter = data.group .== \"python-jupyter\"\n",
    "data.isweb = endswith.(data.group, \"-web\")\n",
    "data.islib = endswith.(data.group, \"-lib\")\n",
    "data.isdatascience = data.group .== \"python-datascience\" .|| data.group .== \"python-jupyter\"\n",
    "data.ispython = data.lang .== \"python\"\n",
    "data.identifier_len_avg = ifelse.(ismissing.(data.identifier_len_avg), 0, data.identifier_len_avg)\n",
    "data.identifier_len_avg = ifelse.(.! isfinite.(data.identifier_len_avg), 0, data.identifier_len_avg)\n",
    "data.function_size_avg = ifelse.(ismissing.(data.function_size_avg), 0, data.function_size_avg)\n",
    "data.function_size_avg = ifelse.(.! isfinite.(data.function_size_avg), 0, data.function_size_avg)\n",
    "data = data[data.filesize .> 0 .&& isfinite.(data.filesize), :]\n",
    "files = data[data.type .== \"file\" .&& data.statements_total .> 3, :]\n",
    "projects = data[data.type .== \"dir-total\" .&& data.statements_total .> 10, :]\n",
    "()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "print_basic_stats (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function print_basic_stats(formula, df, stat_fn)\n",
    "\tformula = GLM.apply_schema(formula, GLM.schema(formula, df))\n",
    "\tresp, pred = GLM.modelcols(formula, df)\n",
    "\tresp_name, pred_names = GLM.coefnames(formula)\n",
    "\tfor i = 1:length(pred_names)\n",
    "\t\tpred_name = pred_names[i]\n",
    "\t\tpred0 = pred[resp .== 0, i]\n",
    "\t\tpred1 = pred[resp .== 1, i]\n",
    "\t\t@printf(\"%60s %8.5f %8.5f\\n\", pred_name, stat_fn(pred0), stat_fn(pred1))\n",
    "\tend\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction of jupyter files 0.18195024514254585 = 1002 / 5507\n",
      "fraction of jupyter projects 0.3488372093023256 = 15 / 43\n",
      "mean file size = 276.9228254948248\n",
      "                                                    filesize 232.93541 474.69062\n",
      "                        expressions_total / statements_total  2.86266  2.65766\n",
      "                           binary_operators_total / filesize  0.01379  0.04857\n",
      "                              chained_calls_total / filesize  0.02129  0.01062\n",
      "                                 class_defs_total / filesize  0.01864  0.00170\n",
      "                                 conditions_total / filesize  0.04106  0.01022\n",
      "                                 decorators_total / filesize  0.01571  0.00084\n",
      "                             field_accesses_total / filesize  0.17140  0.09472\n",
      "                          field_assignments_total / filesize  0.01303  0.00802\n",
      "                              function_defs_total / filesize  0.05395  0.01355\n",
      "                                           function_size_avg 18.80991 13.98251\n",
      "                                          identifier_len_avg  7.92024  6.63907\n",
      "                                   indexing_total / filesize  0.04298  0.05300\n",
      "                                invocations_total / filesize  0.24868  0.26876\n",
      "                           lambda_functions_total / filesize  0.00267  0.00122\n",
      "                                   literals_total / filesize  0.34805  0.26108\n",
      "                                      loops_total / filesize  0.01725  0.01502\n",
      "        nested_functions_total / max(1, function_defs_total)  0.01996  0.02291\n",
      "                                    slicing_total / filesize  0.00189  0.01447\n",
      "                                try_catches_total / filesize  0.00419  0.00048\n",
      "                       variable_assignments_total / filesize  0.08648  0.12381\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StatsModels.TableRegressionModel{GLM.GeneralizedLinearModel{GLM.GlmResp{Vector{Float64}, Distributions.Bernoulli{Float64}, GLM.LogitLink}, GLM.DensePredChol{Float64, LinearAlgebra.CholeskyPivoted{Float64, Matrix{Float64}, Vector{Int64}}}}, Matrix{Float64}}\n",
       "\n",
       "isjupyter ~ 0 + filesize + :(expressions_total / statements_total) + :(binary_operators_total / filesize) + :(chained_calls_total / filesize) + :(class_defs_total / filesize) + :(conditions_total / filesize) + :(decorators_total / filesize) + :(field_accesses_total / filesize) + :(field_assignments_total / filesize) + :(function_defs_total / filesize) + function_size_avg + identifier_len_avg + :(indexing_total / filesize) + :(invocations_total / filesize) + :(lambda_functions_total / filesize) + :(literals_total / filesize) + :(loops_total / filesize) + :(nested_functions_total / max(1, function_defs_total)) + :(slicing_total / filesize) + :(try_catches_total / filesize) + :(variable_assignments_total / filesize)\n",
       "\n",
       "Coefficients:\n",
       "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
       "                                                              Coef.   Std. Error       z  Pr(>|z|)       Lower 95%     Upper 95%\n",
       "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
       "filesize                                                0.000812445   9.60729e-5    8.46    <1e-16     0.000624146    0.00100074\n",
       "expressions_total / statements_total                   -0.210686      0.0423523    -4.97    <1e-06    -0.293695      -0.127677\n",
       "binary_operators_total / filesize                      30.0659        2.13595      14.08    <1e-44    25.8795        34.2523\n",
       "chained_calls_total / filesize                         -3.04906       3.72572      -0.82    0.4131   -10.3513         4.25322\n",
       "class_defs_total / filesize                           -76.4334       11.3538       -6.73    <1e-10   -98.6865       -54.1803\n",
       "conditions_total / filesize                           -49.7027        4.01597     -12.38    <1e-34   -57.5738       -41.8315\n",
       "decorators_total / filesize                           -55.0535       11.7916       -4.67    <1e-05   -78.1647       -31.9423\n",
       "field_accesses_total / filesize                         0.101543      1.04315       0.10    0.9225    -1.94298        2.14607\n",
       "field_assignments_total / filesize                     28.1834        3.76741       7.48    <1e-13    20.7994        35.5674\n",
       "function_defs_total / filesize                        -47.8676        4.06232     -11.78    <1e-31   -55.8296       -39.9056\n",
       "function_size_avg                                      -0.0394318     0.00457682   -8.62    <1e-17    -0.0484022     -0.0304615\n",
       "identifier_len_avg                                     -0.230599      0.0456827    -5.05    <1e-06    -0.320136      -0.141063\n",
       "indexing_total / filesize                              12.5611        1.58146       7.94    <1e-14     9.4615        15.6607\n",
       "invocations_total / filesize                            9.2632        0.698443     13.26    <1e-39     7.89428       10.6321\n",
       "lambda_functions_total / filesize                       9.03493      15.3992        0.59    0.5574   -21.1469        39.2167\n",
       "literals_total / filesize                              -1.94996       0.339823     -5.74    <1e-08    -2.616         -1.28392\n",
       "loops_total / filesize                                  2.56001       4.10645       0.62    0.5330    -5.48849       10.6085\n",
       "nested_functions_total / max(1, function_defs_total)    0.617948      0.754129      0.82    0.4125    -0.860119       2.09601\n",
       "slicing_total / filesize                               32.2884        6.06613       5.32    <1e-06    20.399         44.1778\n",
       "try_catches_total / filesize                          -87.0047       16.8202       -5.17    <1e-06  -119.972        -54.0376\n",
       "variable_assignments_total / filesize                   6.35554       1.25995       5.04    <1e-06     3.88608        8.825\n",
       "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compared_groups(g) = g in [\"python-web\", \"python-jupyter\"]\n",
    "# compared_groups(g) = g in [\"python-datascience\", \"python-jupyter\"]\n",
    "# compared_groups(g) = startswith(g, \"python-\")\n",
    "py = projects[compared_groups.(projects.group), :]\n",
    "py_files = files[compared_groups.(files.group), :]\n",
    "\n",
    "println(\"fraction of jupyter files \", mean(py_files.isjupyter), \" = \", sum(py_files.isjupyter), \" / \", size(py_files, 1))\n",
    "println(\"fraction of jupyter projects \", mean(py.isjupyter), \" = \", sum(py.isjupyter), \" / \", size(py, 1))\n",
    "println(\"mean file size = \", mean(py_files.filesize))\n",
    "formula = GLM.@formula(isjupyter ~\n",
    "\tfilesize +\n",
    "\t(expressions_total / statements_total) + # number of expressions per statement\n",
    "\t(binary_operators_total / filesize) +\n",
    "\t(chained_calls_total / filesize) +\n",
    "\t(class_defs_total / filesize) +\n",
    "\t(conditions_total / filesize) +\n",
    "\t(decorators_total / filesize) +\n",
    "\t(field_accesses_total / filesize) +\n",
    "\t(field_assignments_total / filesize) +\n",
    "\t(function_defs_total / filesize) +\n",
    "\tfunction_size_avg +\n",
    "\t(identifier_len_avg) +\n",
    "\t(indexing_total / filesize) +\n",
    "\t(invocations_total / filesize) +\n",
    "\t(lambda_functions_total / filesize) +\n",
    "\t(literals_total / filesize) +\n",
    "\t(loops_total / filesize) +\n",
    "\t(nested_functions_total / max(1, function_defs_total)) +\n",
    "\t(slicing_total / filesize) +\n",
    "\t(try_catches_total / filesize) +\n",
    "\t(variable_assignments_total / filesize) +\n",
    "\t0\n",
    "\t)\n",
    "# print_basic_stats(formula, py_files, median)\n",
    "print_basic_stats(formula, py_files, mean)\n",
    "# print_basic_stats(formula, py_files, std)\n",
    "GLM.glm(formula, py_files, GLM.Bernoulli(), GLM.LogitLink())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compared_groups(g) = g in [\"python-jupyter\", \"cs-lib\"]\n",
    "pyvscsharp = files[compared_groups.(files.group), :]\n",
    "formula = GLM.@formula(ispython ~\n",
    "\t# filesize +\n",
    "\t(expressions_total / statements_total) + # number of expressions per statement\n",
    "\t(binary_operators_total / filesize) +\n",
    "\t(chained_calls_total / filesize) +\n",
    "\t# (class_defs_total / filesize) +\n",
    "\t(conditions_total / filesize) +\n",
    "\t# (decorators_total / filesize) +\n",
    "\t(field_accesses_total / filesize) +\n",
    "\t(field_assignments_total / filesize) +\n",
    "\t# (function_defs_total / filesize) +\n",
    "\tfunction_size_avg +\n",
    "\t(identifier_len_avg) +\n",
    "\t(indexing_total / filesize) +\n",
    "\t(invocations_total / filesize) +\n",
    "\t(lambda_functions_total / filesize) +\n",
    "\t(literals_total / filesize) +\n",
    "\t(loops_total / filesize) +\n",
    "\t# (nested_functions_total / max(1, function_defs_total)) +\n",
    "\t# (slicing_total / filesize) +\n",
    "\t# (try_catches_total / filesize) +\n",
    "\t(variable_assignments_total / filesize) +\n",
    "\t0\n",
    ")\n",
    "model = GLM.glm(formula, pyvscsharp, GLM.Bernoulli(), GLM.LogitLink())\n",
    "println(model)\n",
    "\n",
    "println(typeof(Float64.(GLM.modelmatrix(formula, projects))))\n",
    "isdatascience_pred = GLM.predict(model, Float64.(GLM.modelmatrix(formula, projects)))\n",
    "\n",
    "println(DataFrame(group = projects.group, dir = projects.dir, isds = isdatascience_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
